# IGDB Game Recommendation System

Ett komplett system fÃ¶r att samla speldata frÃ¥n externa API:er, trÃ¤na ML-modeller och servera spelrekommendationer via en web-applikation.

## Arkitektur

Projektet Ã¤r uppdelat i tvÃ¥ huvudsakliga pipelines:

### ğŸ­ Data Pipeline (Fabriks-pipeline)

- **Ingestion**: Samlar data frÃ¥n externa API:er
- **Processing**: StÃ¤dar och transformerar rÃ¥data
- **Training**: TrÃ¤nar ML-modeller fÃ¶r spelrekommendationer
- **Deployment**: Distribuerar trÃ¤nade modeller

### ğŸª Web App (Butiks-pipeline)

- **API**: Backend som serverar rekommendationer
- **Frontend**: AnvÃ¤ndargrÃ¤nssnitt fÃ¶r sÃ¶kning och rekommendationer
- **Deployment**: Applikationsdistribution

## Projektstruktur

```text
igdb-project/
â”œâ”€â”€ data-pipeline/          # Fabriks-pipeline
â”‚   â”œâ”€â”€ ingestion/         # API data collection
â”‚   â”œâ”€â”€ processing/        # Data cleaning & transformation
â”‚   â”œâ”€â”€ training/          # ML model training
â”‚   â””â”€â”€ deployment/        # Model serving setup
â”œâ”€â”€ web-app/               # Butiks-pipeline
â”‚   â”œâ”€â”€ api/              # Backend API
â”‚   â”œâ”€â”€ frontend/         # User interface
â”‚   â””â”€â”€ deployment/       # App deployment
â”œâ”€â”€ shared/               # Delad kod (utils, configs)
â”œâ”€â”€ infrastructure/       # Terraform/Pulumi fÃ¶r GCP
â””â”€â”€ docs/                # Dokumentation
```

## Teknisk Stack

- **Cloud**: Google Cloud Platform (GCP)
- **Data Pipeline**: Python, Apache Airflow/Cloud Composer
- **ML**: scikit-learn, TensorFlow/PyTorch
- **Web App**: TBD (React/Vue + FastAPI/Flask)
- **Infrastructure**: Terraform/Pulumi
- **CI/CD**: GitHub Actions

## Utvecklingsprocess

1. **Lokal utveckling** â†’ **Staging** â†’ **Production**
2. **Feature branches** fÃ¶r varje komponent
3. **Separate CI/CD pipelines** fÃ¶r data-pipeline och web-app
4. **Automated testing** pÃ¥ bÃ¥de kod och data quality

## Kom igÃ¥ng

```bash
# Klona repository
git clone <repository-url>
cd igdb-project

# Installera dependencies (kommer senare)
# pip install -r requirements.txt

# KÃ¶r lokalt (kommer senare)
# python -m data_pipeline.ingestion.main
```

## Status

âœ… **Phase 2 Complete** - Data management and smart ingestion pipeline implemented

### **What's Working**
- **DataManager**: SQLite database with automatic deduplication
- **SmartIngestion**: Intelligent data fetching with re-fetching avoidance
- **IGDB Integration**: Robust API client with rate limiting (4 req/s)
- **Testing**: 24 comprehensive unit tests
- **Code Quality**: Pre-commit hooks, type hints, documentation

### **Quick Start**
```bash
# Install dependencies
python3 -m venv venv
source venv/bin/activate
pip install -e .

# Test smart ingestion (requires IGDB API credentials)
python -m data_pipeline.ingestion.main --smart --limit 100

# Run tests
pytest tests/ -v
```

### **Next Steps**
ğŸ¯ **Phase 3**: End-to-end testing with real IGDB API, ML pipeline development

See `docs/CURRENT_STATUS.md` for detailed next steps and decision points.

## Licens

TBD
